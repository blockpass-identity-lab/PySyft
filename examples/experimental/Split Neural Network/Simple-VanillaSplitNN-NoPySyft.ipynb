{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "# import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[1,1,0,0],[1,0,1,0],[0,1,1,0],[1,1,1,0],[0,0,0,1],[1,0,0,1],[0,1,0,1],[0,0,1,1],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1.]])\n",
    "x.requires_grad_()\n",
    "target = torch.tensor([[0],[0],[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[1],[1.]])\n",
    "\n",
    "\n",
    "#   Variables for performance metrics\n",
    "epochs = 20\n",
    "lr = 0.2\n",
    "counter = 0\n",
    "\n",
    "# Define 2 chained models\n",
    "models = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(4, 3),\n",
    "        nn.Tanh()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(3, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create optimisers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(params=model.parameters(),lr=lr)\n",
    "    for model in models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[-0.0053, -0.0080, -0.0099,  0.1347],\n",
      "        [ 0.0033,  0.0025,  0.0027,  0.4079],\n",
      "        [-0.0140, -0.0167, -0.0184, -1.0661]])\n",
      "tensor(4.5665)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0505, -0.0569, -0.0608,  0.3359],\n",
      "        [-0.0096, -0.0110, -0.0119,  0.2134],\n",
      "        [ 0.0131,  0.0151,  0.0165, -0.6925]])\n",
      "tensor(4.0536)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0955, -0.1044, -0.1091,  0.4753],\n",
      "        [-0.0078, -0.0090, -0.0097,  0.1344],\n",
      "        [ 0.0182,  0.0216,  0.0238, -0.4894]])\n",
      "tensor(3.7991)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.1204, -0.1336, -0.1392,  0.6185],\n",
      "        [-0.0045, -0.0056, -0.0063,  0.1023],\n",
      "        [ 0.0141,  0.0185,  0.0212, -0.3982]])\n",
      "tensor(3.5617)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.1124, -0.1321, -0.1394,  0.7706],\n",
      "        [-0.0013, -0.0025, -0.0033,  0.0908],\n",
      "        [ 0.0075,  0.0135,  0.0171, -0.3704]])\n",
      "tensor(3.2541)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-6.6831e-02, -9.4182e-02, -1.0369e-01,  8.9655e-01],\n",
      "        [ 2.1381e-03,  5.3023e-04, -3.5584e-04,  8.9059e-02],\n",
      "        [-2.3348e-04,  8.0208e-03,  1.3076e-02, -3.7591e-01]])\n",
      "tensor(2.8403)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0144, -0.0470, -0.0587,  0.9333],\n",
      "        [ 0.0053,  0.0032,  0.0020,  0.0905],\n",
      "        [-0.0056,  0.0054,  0.0125, -0.3849]])\n",
      "tensor(2.3331)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0237, -0.0090, -0.0217,  0.8650],\n",
      "        [ 0.0079,  0.0054,  0.0038,  0.0907],\n",
      "        [-0.0070,  0.0063,  0.0153, -0.3747]])\n",
      "tensor(1.7992)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0483,  0.0203,  0.0080,  0.7365],\n",
      "        [ 0.0098,  0.0070,  0.0051,  0.0872],\n",
      "        [-0.0065,  0.0077,  0.0177, -0.3420]])\n",
      "tensor(1.3259)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0507,  0.0287,  0.0180,  0.5912],\n",
      "        [ 0.0100,  0.0073,  0.0052,  0.0797],\n",
      "        [-0.0031,  0.0105,  0.0207, -0.2958]])\n",
      "tensor(0.9640)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0479,  0.0312,  0.0224,  0.4696],\n",
      "        [ 0.0096,  0.0070,  0.0050,  0.0709],\n",
      "        [-0.0007,  0.0117,  0.0214, -0.2509]])\n",
      "tensor(0.7117)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0393,  0.0266,  0.0194,  0.3737],\n",
      "        [ 0.0086,  0.0062,  0.0043,  0.0622],\n",
      "        [ 0.0021,  0.0131,  0.0219, -0.2118]])\n",
      "tensor(0.5414)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0330,  0.0231,  0.0172,  0.3038],\n",
      "        [ 0.0077,  0.0055,  0.0037,  0.0547],\n",
      "        [ 0.0036,  0.0132,  0.0212, -0.1808]])\n",
      "tensor(0.4255)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0272,  0.0193,  0.0144,  0.2515],\n",
      "        [ 0.0067,  0.0048,  0.0031,  0.0484],\n",
      "        [ 0.0047,  0.0132,  0.0204, -0.1562]])\n",
      "tensor(0.3444)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0227,  0.0163,  0.0122,  0.2123],\n",
      "        [ 0.0060,  0.0042,  0.0026,  0.0432],\n",
      "        [ 0.0052,  0.0128,  0.0193, -0.1367]])\n",
      "tensor(0.2859)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0192,  0.0139,  0.0103,  0.1822],\n",
      "        [ 0.0053,  0.0037,  0.0022,  0.0389],\n",
      "        [ 0.0055,  0.0123,  0.0182, -0.1210]])\n",
      "tensor(0.2423)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0165,  0.0120,  0.0089,  0.1586],\n",
      "        [ 0.0048,  0.0033,  0.0019,  0.0354],\n",
      "        [ 0.0056,  0.0118,  0.0171, -0.1083]])\n",
      "tensor(0.2090)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0143,  0.0104,  0.0077,  0.1398],\n",
      "        [ 0.0043,  0.0029,  0.0016,  0.0323],\n",
      "        [ 0.0056,  0.0112,  0.0161, -0.0978]])\n",
      "tensor(0.1829)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0125,  0.0091,  0.0068,  0.1245],\n",
      "        [ 0.0039,  0.0026,  0.0014,  0.0298],\n",
      "        [ 0.0056,  0.0107,  0.0152, -0.0890]])\n",
      "tensor(0.1620)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0111,  0.0081,  0.0060,  0.1119],\n",
      "        [ 0.0036,  0.0024,  0.0013,  0.0276],\n",
      "        [ 0.0054,  0.0102,  0.0143, -0.0816]])\n",
      "tensor(0.1449)\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    # Training Logic\n",
    "    for iter in range(epochs):\n",
    "\n",
    "        # 1) erase previous gradients (if they exist)\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # 2) make a prediction\n",
    "        a  = models[0](x)\n",
    "\n",
    "        # 3) send the activation signal to the next model\n",
    "        remote_a = a.detach()\n",
    "        # re-enable autograd here\n",
    "        remote_a.requires_grad_()\n",
    "\n",
    "        pred =  models[1](remote_a)\n",
    "\n",
    "        # 3) calculate how much we missed\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        # 4) figure out which weights caused us to miss\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5) Backprop gradient to model behind\n",
    "        grad_a = remote_a.grad.clone()\n",
    "        \n",
    "        # 5) Go backward from grad_a \n",
    "        print(models[0][0].weight.grad)\n",
    "        a.backward(grad_a)\n",
    "        print(models[0][0].weight.grad)\n",
    "\n",
    "        # 5) change the weights\n",
    "        for opt in optimizers:\n",
    "            opt.step()\n",
    "\n",
    "        # 6) print our progress\n",
    "        # Do not use .data\n",
    "        print(loss.detach())\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
