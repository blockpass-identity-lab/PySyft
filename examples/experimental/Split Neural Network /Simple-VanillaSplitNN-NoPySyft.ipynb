{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.autograd import Variable\n",
    "# import pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0,0,0,0],[1,0,0,0],[0,1,0,0],[0,0,1,0],[1,1,0,0],[1,0,1,0],[0,1,1,0],[1,1,1,0],[0,0,0,1],[1,0,0,1],[0,1,0,1],[0,0,1,1],[1,1,0,1],[1,0,1,1],[0,1,1,1],[1,1,1,1.]])\n",
    "x.requires_grad_()\n",
    "target = torch.tensor([[0],[0],[0],[0],[0],[0],[0],[0],[1],[1],[1],[1],[1],[1],[1],[1.]])\n",
    "\n",
    "\n",
    "#   Variables for performance metrics\n",
    "epochs = 20\n",
    "lr = 0.2\n",
    "counter = 0\n",
    "\n",
    "# Define 2 chained models\n",
    "models = [\n",
    "    nn.Sequential(\n",
    "        nn.Linear(4, 3),\n",
    "        nn.Tanh()\n",
    "    ),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(3, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create optimisers for each segment and link to their segment\n",
    "optimizers = [\n",
    "    optim.SGD(params=model.parameters(),lr=lr)\n",
    "    for model in models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[ 0.0558,  0.0670,  0.0665,  0.3947],\n",
      "        [-0.0059, -0.0040, -0.0066, -0.0304],\n",
      "        [ 0.0059,  0.0073,  0.0082,  0.0533]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0938,  0.3042,  0.3276, -0.1152],\n",
      "        [ 0.1320, -0.3280,  0.2153, -0.4838],\n",
      "        [ 0.4335,  0.2187, -0.1787,  0.0512]], requires_grad=True)\n",
      "tensor(4.0880)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0337,  0.0499,  0.0604,  0.4350],\n",
      "        [ 0.0449,  0.0225,  0.0570,  0.3011],\n",
      "        [-0.0031, -0.0038, -0.0053, -0.0451]])\n",
      "Parameter containing:\n",
      "tensor([[-0.1050,  0.2908,  0.3143, -0.1941],\n",
      "        [ 0.1332, -0.3272,  0.2166, -0.4778],\n",
      "        [ 0.4323,  0.2172, -0.1803,  0.0405]], requires_grad=True)\n",
      "tensor(3.8292)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0014,  0.0238,  0.0525,  0.5125],\n",
      "        [ 0.0506, -0.0085,  0.0864,  0.5650],\n",
      "        [-0.0021, -0.0024, -0.0082, -0.0962]])\n",
      "Parameter containing:\n",
      "tensor([[-0.1117,  0.2809,  0.3023, -0.2811],\n",
      "        [ 0.1242, -0.3317,  0.2052, -0.5380],\n",
      "        [ 0.4329,  0.2180, -0.1793,  0.0496]], requires_grad=True)\n",
      "tensor(3.5561)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0581, -0.0304,  0.0258,  0.5733],\n",
      "        [-0.0043, -0.1136,  0.0672,  0.7422],\n",
      "        [ 0.0047,  0.0059, -0.0052, -0.1166]])\n",
      "Parameter containing:\n",
      "tensor([[-0.1120,  0.2761,  0.2918, -0.3836],\n",
      "        [ 0.1141, -0.3300,  0.1879, -0.6510],\n",
      "        [ 0.4333,  0.2185, -0.1777,  0.0688]], requires_grad=True)\n",
      "tensor(3.1804)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.1241, -0.0918, -0.0032,  0.5960],\n",
      "        [-0.0878, -0.2440,  0.0228,  0.8138],\n",
      "        [ 0.0113,  0.0140, -0.0016, -0.1136]])\n",
      "Parameter containing:\n",
      "tensor([[-0.1004,  0.2822,  0.2866, -0.4983],\n",
      "        [ 0.1149, -0.3073,  0.1745, -0.7994],\n",
      "        [ 0.4324,  0.2173, -0.1766,  0.0921]], requires_grad=True)\n",
      "tensor(2.6832)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.1338, -0.0922,  0.0204,  0.6011],\n",
      "        [-0.0850, -0.2669,  0.0532,  0.8328],\n",
      "        [ 0.0103,  0.0132, -0.0048, -0.1011]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0756,  0.3005,  0.2873, -0.6175],\n",
      "        [ 0.1325, -0.2585,  0.1699, -0.9622],\n",
      "        [ 0.4301,  0.2145, -0.1763,  0.1149]], requires_grad=True)\n",
      "tensor(2.0917)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.1115, -0.0584,  0.0518,  0.5523],\n",
      "        [-0.0468, -0.2145,  0.0883,  0.7511],\n",
      "        [ 0.0075,  0.0092, -0.0083, -0.0868]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0488,  0.3190,  0.2832, -0.7377],\n",
      "        [ 0.1495, -0.2051,  0.1593, -1.1287],\n",
      "        [ 0.4281,  0.2119, -0.1753,  0.1351]], requires_grad=True)\n",
      "tensor(1.5105)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0903, -0.0301,  0.0555,  0.4575],\n",
      "        [-0.0288, -0.1568,  0.0792,  0.5985],\n",
      "        [ 0.0059,  0.0062, -0.0084, -0.0715]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0265,  0.3307,  0.2728, -0.8481],\n",
      "        [ 0.1589, -0.1622,  0.1417, -1.2790],\n",
      "        [ 0.4266,  0.2100, -0.1737,  0.1524]], requires_grad=True)\n",
      "tensor(1.0527)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0637, -0.0030,  0.0555,  0.3708],\n",
      "        [-0.0071, -0.0976,  0.0712,  0.4686],\n",
      "        [ 0.0040,  0.0030, -0.0083, -0.0587]])\n",
      "Parameter containing:\n",
      "tensor([[-0.0084,  0.3367,  0.2617, -0.9397],\n",
      "        [ 0.1646, -0.1308,  0.1258, -1.3986],\n",
      "        [ 0.4254,  0.2088, -0.1720,  0.1667]], requires_grad=True)\n",
      "tensor(0.7435)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0504,  0.0057,  0.0447,  0.2957],\n",
      "        [-0.0040, -0.0680,  0.0521,  0.3619],\n",
      "        [ 0.0033,  0.0017, -0.0069, -0.0483]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0043,  0.3373,  0.2506, -1.0138],\n",
      "        [ 0.1660, -0.1113,  0.1116, -1.4924],\n",
      "        [ 0.4246,  0.2082, -0.1704,  0.1785]], requires_grad=True)\n",
      "tensor(0.5456)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0374,  0.0128,  0.0389,  0.2426],\n",
      "        [ 0.0020, -0.0449,  0.0428,  0.2900],\n",
      "        [ 0.0025,  0.0006, -0.0062, -0.0407]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0144,  0.3361,  0.2417, -1.0729],\n",
      "        [ 0.1668, -0.0977,  0.1012, -1.5647],\n",
      "        [ 0.4239,  0.2078, -0.1690,  0.1881]], requires_grad=True)\n",
      "tensor(0.4174)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-3.0080e-02,  1.4176e-02,  3.2179e-02,  2.0172e-01],\n",
      "        [ 2.9208e-03, -3.2872e-02,  3.3487e-02,  2.3636e-01],\n",
      "        [ 2.0684e-03,  1.5904e-04, -5.2888e-03, -3.4821e-02]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0219,  0.3336,  0.2339, -1.1215],\n",
      "        [ 0.1664, -0.0887,  0.0926, -1.6227],\n",
      "        [ 0.4234,  0.2077, -0.1677,  0.1963]], requires_grad=True)\n",
      "tensor(0.3312)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-2.4335e-02,  1.4676e-02,  2.7413e-02,  1.7133e-01],\n",
      "        [ 3.7735e-03, -2.4521e-02,  2.7335e-02,  1.9756e-01],\n",
      "        [ 1.7226e-03, -1.4900e-04, -4.6366e-03, -3.0327e-02]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0279,  0.3308,  0.2275, -1.1618],\n",
      "        [ 0.1659, -0.0821,  0.0859, -1.6700],\n",
      "        [ 0.4230,  0.2077, -0.1667,  0.2032]], requires_grad=True)\n",
      "tensor(0.2709)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0202,  0.0143,  0.0236,  0.1479],\n",
      "        [ 0.0040, -0.0190,  0.0226,  0.1683],\n",
      "        [ 0.0015, -0.0003, -0.0041, -0.0268]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0327,  0.3278,  0.2220, -1.1961],\n",
      "        [ 0.1651, -0.0772,  0.0804, -1.7095],\n",
      "        [ 0.4227,  0.2077, -0.1658,  0.2093]], requires_grad=True)\n",
      "tensor(0.2270)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0171,  0.0137,  0.0205,  0.1295],\n",
      "        [ 0.0040, -0.0152,  0.0191,  0.1457],\n",
      "        [ 0.0013, -0.0004, -0.0036, -0.0239]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0368,  0.3249,  0.2173, -1.2257],\n",
      "        [ 0.1643, -0.0734,  0.0759, -1.7432],\n",
      "        [ 0.4224,  0.2078, -0.1649,  0.2147]], requires_grad=True)\n",
      "tensor(0.1941)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0147,  0.0129,  0.0180,  0.1148],\n",
      "        [ 0.0039, -0.0125,  0.0163,  0.1279],\n",
      "        [ 0.0011, -0.0004, -0.0033, -0.0216]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0402,  0.3222,  0.2132, -1.2516],\n",
      "        [ 0.1635, -0.0704,  0.0721, -1.7723],\n",
      "        [ 0.4221,  0.2079, -0.1642,  0.2195]], requires_grad=True)\n",
      "tensor(0.1686)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0128,  0.0121,  0.0160,  0.1028],\n",
      "        [ 0.0037, -0.0105,  0.0141,  0.1136],\n",
      "        [ 0.0010, -0.0005, -0.0030, -0.0197]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0431,  0.3196,  0.2096, -1.2745],\n",
      "        [ 0.1627, -0.0679,  0.0688, -1.7979],\n",
      "        [ 0.4219,  0.2079, -0.1635,  0.2238]], requires_grad=True)\n",
      "tensor(0.1485)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0113,  0.0114,  0.0143,  0.0929],\n",
      "        [ 0.0035, -0.0089,  0.0124,  0.1018],\n",
      "        [ 0.0009, -0.0005, -0.0027, -0.0181]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0457,  0.3172,  0.2064, -1.2951],\n",
      "        [ 0.1620, -0.0658,  0.0660, -1.8206],\n",
      "        [ 0.4217,  0.2080, -0.1630,  0.2277]], requires_grad=True)\n",
      "tensor(0.1323)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0100,  0.0106,  0.0129,  0.0846],\n",
      "        [ 0.0034, -0.0077,  0.0109,  0.0921],\n",
      "        [ 0.0009, -0.0005, -0.0025, -0.0167]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0479,  0.3149,  0.2035, -1.3137],\n",
      "        [ 0.1613, -0.0640,  0.0635, -1.8410],\n",
      "        [ 0.4215,  0.2081, -0.1624,  0.2313]], requires_grad=True)\n",
      "tensor(0.1190)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[-0.0090,  0.0100,  0.0118,  0.0775],\n",
      "        [ 0.0032, -0.0068,  0.0097,  0.0839],\n",
      "        [ 0.0008, -0.0005, -0.0023, -0.0155]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.0500,  0.3128,  0.2009, -1.3306],\n",
      "        [ 0.1606, -0.0624,  0.0614, -1.8594],\n",
      "        [ 0.4213,  0.2082, -0.1619,  0.2347]], requires_grad=True)\n",
      "tensor(0.1079)\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    # Training Logic\n",
    "    for iter in range(epochs):\n",
    "\n",
    "        # 1) erase previous gradients (if they exist)\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # 2) make a prediction\n",
    "        a  = models[0](x)\n",
    "\n",
    "        # 3) send the activation signal to the next model\n",
    "        remote_a = a.detach()\n",
    "        # re-enable autograd here\n",
    "        remote_a.requires_grad_()\n",
    "\n",
    "        pred =  models[1](remote_a)\n",
    "\n",
    "        # 3) calculate how much we missed\n",
    "        loss = ((pred - target)**2).sum()\n",
    "\n",
    "        # 4) figure out which weights caused us to miss\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5) Backprop gradient to model behind\n",
    "        grad_a = remote_a.grad.clone()\n",
    "        \n",
    "        # 5) Go backward from grad_a \n",
    "        print(models[0][0].weight.grad)\n",
    "        a.backward(grad_a)\n",
    "        print(models[0][0].weight.grad)\n",
    "        print(models[0][0].weight)\n",
    "\n",
    "\n",
    "        # 5) change the weights\n",
    "        for opt in optimizers:\n",
    "            opt.step()\n",
    "\n",
    "        # 6) print our progress\n",
    "        # Do not use .data\n",
    "        print(loss.detach())\n",
    "        \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
